
<html>
<title>Circular Accessible Depth: A Robust Traversability Representation for UGV Navigation</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta name="format-detection" content="telephone=no">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <!--Import Google Icon Font-->
      <link href="http://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
      <!--Import materialize.css-->
      <link type="text/css" rel="stylesheet" href="css/materialize.min.css"  media="screen,projection"/>
      <!--Let browser know website is optimized for mobile-->
      <meta name="viewport" content="width=device-width, initial-scale=1.0"/>    

<body>
	<br />
    <center><h2 class="black-text" style="padding-left: 200px; padding-right: 200px;"><b>Circular Accessible Depth: A Robust Traversability Representation for UGV Navigation</b></h2></center><br>
    <center><font size="5"> <class="gray-text">Shikuan Xie, Ran Song, Yuenan Zhao, Xueqin Huang, Yinbin Li, and Wei Zhang</font></center><br>
    <center><font size="4">School of Control Science and Engineering, Shandong University&nbsp;&nbsp;</font></center><br>
    <center><font size="4"><b>IEEE Transactions on Robotics&nbsp;&nbsp;</b></font></center><br><br>
    <p style="padding-left: 210px;"><h5><b>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;● Abstract</b></p></h5>
    <p style="padding-left: 210px; padding-right: 210px; text-align:justify; text-justify:inter-ideograph;"><font size="4">In this paper, we present the Circular Accessible Depth (CAD), a robust traversability representation for an unmanned ground vehicle (UGV) to learn traversability in various scenarios containing irregular obstacles.
To predict CAD, we propose a neural network, namely CADNet, with an attention-based multi-frame point cloud fusion module, Stability-Attention Module (SAM), to encode the spatial features from point clouds captured by LiDAR.
CAD is designed based on the polar coordinate system and focuses on predicting the border of traversable area. 
Since it encodes the spatial information of the surrounding environment, which enables a semi-supervised learning for the CADNet, and thus desirably avoids annotating a large amount of data.
Extensive experiments demonstrate that CAD outperforms baselines in terms of robustness and precision.
We also implement our method on a real UGV and show that it performs well in real-world scenarios.</font>
    </p><br><br>
    <p style="padding-left: 210px;"><h5><b>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;● Contributions</b></p></h5>
    <p style="padding-left: 210px; padding-right: 210px; text-align:justify; text-justify:inter-ideograph;"><font size="4">We propose Circular Accessible Depth, a robust traversability representation for UGV navigation. We present the CADNet, trained in a semi-supervised manner, to extract the features with regard to the spatial distribution of point clouds and predict CAD. In the CADNet, we design a Stability-Attention Module to tackle the interference of dynamic objects in the fusion of point clouds from multiple frames.</font>
    </p><center><img src="./image/pipeline.png" width="60%">
    
<br> <b><font size="4">Fig 1: Overview of the proposed method.</font></b>
</center><br><br>
<p style="padding-left: 210px;"><h5><b>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;● Video:</b></p></h5>

<center>
     <br><br>
<iframe width="672" height="378" src="https://www.youtube.com/embed/Ef_MEbjhTJg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</center>

<br><br>

<!--
    <section class="section">
  <div class="columns is-centered">
    <div class="column is-full-width">
      <div class="is-vcentered interpolation-panel">
        <h4 class="title is-3" style="text-align: center;"><b>Related Work</b></h4>
        <div class="content is-centered has-text-centered">&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
              <font size="4">This work is part of our series of research on learning based control of legged robots. Please check out other works below.</font>
        </div>
        <br><br>
        <div class="container">
          <div class="subtitle is-centered">
            <table width="100%">
              <tbody><tr>
                <td width="100%">
                <div style="float:left;margin-right:30px;margin-left:30px;">
                <iframe width="448" height="252" src="https://www.youtube.com/embed/22JcHr4zm9A?si=8ee9KYji-pQx-A8Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                </div>
                <br><br><br>
                <font size="3"><b>A Hierarchical Framework for Quadruped Locomotion Based on Reinforcement Learning </b></font><br>
                <br>
                <font size="3">Wenhao Tan, Xing Fang, Wei Zhang, Ran Song, Teng Chen, and Yibin Li </font><br>
                <br>
                <font size="3">IROS 2021 <br> <br> <br>
              </td></tr>
            </tbody></table>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
 -->
<!--h5 style="padding-left: 210px;"><blockquote>Implicit method for robot imitation learning</blockquote></h5
Simulation and real-world experiments video of our implicit method for robot imitation learning
Real world experiments video of our explicit method for robot imitation learning
-->
<!--Import jQuery before materialize.js-->
      <script type="text/javascript" src="js/jquery-2.1.1.min.js"></script>
      <script type="text/javascript" src="js/materialize.min.js"></script>
</body>
</html>
