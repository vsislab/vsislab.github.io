
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Learning to Navigate Sequential Environments: A Continual Learning Benchmark for Multi-modal Navigation</title>
    <!-- CSS -->
        <link href='http://fonts.googleapis.com/css?family=Quicksand:300,400' rel='stylesheet' type='text/css'>
        <link href='http://fonts.googleapis.com/css?family=Oxygen:400,300' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="css/style.css" type="text/css" media="screen" />
    <!-- ENDS CSS -->

        <!--script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-89797207-1', 'auto');
          ga('send', 'pageview');

        </script-->

        <!-- ENDS JS -->  
  </head> 
  <body>
    <!-- MAIN -->
    <div id="main">

            <div id="match-nav-wrapper">
                <div id="match-nav-bar">

                    <table>
                        <thead>
                            <tr>
                                <!--th width="10%"><a href="#">Home</a></th-->
                                <!--th width="30%"><a href="#video-explicit">Demonstration of the explicit method</a></th>
                                <th width="30%"><a href="#video-implicit">Demonstration of the implicit method</a></th-->
                                <!--th width="15%"></th-->
                            </tr>
                        </thead>
                    </table>

                </div>
            </div>

      <!-- HEADER -->
      <div id="home-header">
      
            <div id="match-wrapper">

                <!--h5><a href="#"><img src="image/logo.png"></a></h5-->

              

                <h2>Learning to Navigate Sequential Environments: A Continual Learning Benchmark for Multi-modal Navigation</h2>
                <center>
                  YinDuo Xie<sup>1</sup>, Qian Zhang<sup>1</sup>, Ran Song<sup>1*</sup>,  Paul L. Rosin<sup>2</sup>, Wei Zhang<sup>1</sup><br />
                  <font size=2>School of Control Science and Engineering, Shandong University</font>    
                </center>
                <br><strong>Abstract</strong>
                <p style="text-align:justify; text-justify:inter-ideograph;">
                Current state-of-the-art robot navigation methods are typically evaluated in the individual task setting, overlooking the continual learning (CL) tasks in sequential environments. In this paper, we present CLBMN, a benchmark specifically designed to investigate multi-modal robot navigation tasks within a CL paradigm. First, we construct a dataset derived from five scenarios: daytime, nighttime, rainy conditions, highway, and field. It contains three modalities: images, point clouds, and odometry data, with a total of 10,000 samples. Then, we present a foundational navigation framework that decouples perception from control, generating velocity commands end-to-end based on multi-modal data. We also propose the momentum update method as a novel continual learning algorithm. Furthermore, we conduct three evaluation metrics specifically designed to assess the robot's navigation performance across different scenarios. Experiments demonstrate that our benchmark is feasible for studying multi-modal robot navigation in sequential environments.
				 <a href="https://drive.google.com/file/d/19jLcdDeCWlogXNWBIeiOquHgxtOa8JzU/view?usp=drive_link">Datasets Available Here1</a></p>
		     		 <a href="链接: https://pan.baidu.com/s/1pKwUuy4jNzCJ04dYc_nIzg?pwd=m2m6 提取码: m2m6">Datasets Available Here2</a></p>

                <h1>Overview</h1>
                <div id="ships-structure-img"><img src="image/ships.png" style="width: 100%; height: auto;"></div>
		   
		    



		<h1>Landmark-based key area detection for ships</h1>	
                    <div id="aread"><img src="image/areadetect.png" style="width: 100%; height: auto;"></div>
		<h1>Landmark-based Ship Detection</h1>	
		    <div id="3dbox"><img src="image/3dbox.png" style="width: 100%; height: auto;"></div>

		<h1>Distribution of the number of ships in different categories in the SLAD</h1>	
		    <div id="cate"><img src="image/catenum.png" style="width: 100%; height: auto;"></div>

		<h1>Three annotated visualisations of the SLAD</h1>	
		    <div id="catev"><img src="image/three.png" style="width: 100%; height: auto;"></div>
		    
		<h1>Visualisation of different values of β</h1>	
		    <div id="aefvis"><img src="image/aefvis.png" style="width: 100%; height: auto;"></div>
		<h1>Ship classification results on the data generated with different values of β</h1>	
		    <div id="aef"><img src="image/aef.png" style="width: 100%; height: auto;"></div>
		<h1>Performance of training models with different values of β</h1>	
		    <div id="ap"><img src="image/aef_performence.png" style="width: 100%; height: auto;"></div>
		<h1>CAM image visualisation of ship images using "the ship" as CLIP input text</h1>	
		    <div id="ap"><img src="image/CLIP-cam.png" style="width: 100%; height: auto;"></div>
			
		    
             
		    

              </div>
      <!-- ENDS Footer -->
  </body>
</html>
